"""
Main script for refolding pipeline on unconditional generation (Colab version).
The refolding pipeline use ESMFold as default.
This version removes Foldseek dependencies for running in Colab environment.

To run AlphaFold2: 
> python scaffold_lab/unconditional/refolding_colab.py inference.predict_method='AlphaFold2'

To run ESMFold and AlphaFold2 simultaneously:
> python scaffold_lab/unconditional/refolding_colab.py inference.predict_method='[AlphaFold2, ESMFold]'

"""

import os
import tree
import time
import numpy as np
import hydra
import torch
import subprocess
import logging
import warnings
import pandas as pd
import sys
import rootutils
import shutil
import GPUtil
from pathlib import Path
from typing import Optional, Dict, Union, List
from omegaconf import DictConfig, OmegaConf
from collections import defaultdict

import esm
import biotite.structure.io as strucio
from biotite.sequence.io import fasta


path = rootutils.find_root(search_from='./', indicator=[".git", "setup.cfg"])
rootutils.set_root(
    path=path, # path to the root directory
    project_root_env_var=True, # set the PROJECT_ROOT environment variable to root directory
    dotenv=True, # load environment variables from .env if exists in root directory
    pythonpath=True, # add root directory to the PYTHONPATH (helps with imports)
    cwd=True, # change current working directory to the root directory (helps with filepaths)
)

import scaffold_lab
from analysis import utils as au
from data import structure_utils as su
from analysis import plot as pu


class UnconditionalRefolder:

    """
    Perform refolding analysis on a set of protein backbones.
    Organized by the following steps:
    1. Config initialization
    2. Run ProteinMPNN on a given set of PDB files
    3. Run ESMFold / AlphaFold2 on sequences generated by ProteinMPNN ()
    4. Calculate the metrics (RMSD, TM-score, pLDDT, etc.) and write information into a csv file.
    
    One can also modify this script to perform fixed backbone design and evaluations on refoldability.
    Adapted from https://github.com/jasonkyuyim/se3_diffusion/blob/master/experiments/inference_se3_diffusion.py
    """
    
    def __init__(
        self,
        conf:DictConfig,
        conf_overrides: Dict=None
        ):
        
        self._log = logging.getLogger(self.__class__.__name__)
        warnings.filterwarnings("ignore", module="biotite.*|psutil.*|matplotlib.*", category=UserWarning)
        
        OmegaConf.set_struct(conf, False)
        
        self._package_dir = "/".join(scaffold_lab.__path__._path[0].split("/")[:-1])
        self._conf = conf
        self._infer_conf = conf.inference
        self._sample_conf = self._infer_conf.samples

        # Sanity check
        if self._sample_conf.seq_per_sample < self._sample_conf.mpnn_batch_size:
            raise ValueError(f'Sequences per sample {self._sample_conf.seq_per_sample} < \
            batch size {self._sample_conf.mpnn_batch_size}!')
        
        self._rng = np.random.default_rng(self._infer_conf.seed)
        
        # Set-up accelerator
        if torch.cuda.is_available():
            if self._infer_conf.gpu_id is None:
                available_gpus = ''.join(
                    [str(x) for x in GPUtil.getAvailable(
                        order="memory", limit = 8)]
                )
                self.device = f'cuda:{available_gpus[0]}'
            else:
                self.device = f'cuda:{self._infer_conf.gpu_id}'
        else:
            self.device = 'cpu'
        self._log.info(f'Using device: {self.device}')

        # Customizing different structure prediction methods 
        self._forward_folding = self._infer_conf.predict_method
        if 'AlphaFold2' in self._forward_folding:
            self._af2_conf = self._infer_conf.af2
            colabfold_path = self._af2_conf.executive_colabfold_path
            current_path = os.environ.get('PATH', '')
            os.environ['PATH'] = colabfold_path + ":" + current_path
            if self.device == 'cpu':
                self._log.info(f"You're running AlphaFold2 on {self.device}.")
        
        # Set-up directories
        output_dir = self._infer_conf.output_dir
        
        self._output_dir = output_dir
        os.makedirs(self._output_dir, exist_ok=True)
        self._pmpnn_dir = os.path.join(self._package_dir, self._infer_conf.pmpnn_dir)
        self._sample_dir = self._infer_conf.backbone_pdb_dir
        self._CA_only = self._infer_conf.CA_only
        self._hide_GPU_from_pmpnn = self._infer_conf.hide_GPU_from_pmpnn
        
        # Save config
        config_folder = os.path.basename(Path(self._output_dir))
        config_path = os.path.join(self._output_dir, f"{config_folder}.yaml")
        with open(config_path, 'w') as f:
            OmegaConf.save(config=self._conf, f=f)
        self._log.info(f'Saving self-consistency config to {config_path}')
        
        # Load models and experiment
        if 'cuda' in self.device:
            self._folding_model = esm.pretrained.esmfold_v1().eval()
        elif self.device == 'cpu': # ESMFold is not supported for half-precision model when running on CPU
            self._folding_model = esm.pretrained.esmfold_v1().float().eval()
        self._folding_model = self._folding_model.to(self.device)
    
    def run_sampling(self):
        
        # Run ProteinMPNN
        for pdb_file in os.listdir(self._sample_dir):

            naming_number = 1
            if ".pdb" not in pdb_file:
                continue

            # Backbone name handling
            all_name = os.path.splitext(pdb_file)[0]

            backbone_name = os.path.splitext(pdb_file)[0]
            print(f'sample_dir: {self._sample_dir}')
            #basename_dir = os.path.basename(os.path.normpath(self._sample_dir))
            #backbone_dir = os.path.join(self._output_dir, basename_dir, f'{backbone_name}')
            # Save outputs
            backbone_dir = os.path.join(self._output_dir, backbone_name)
            if "ESMFold" in self._forward_folding:
                summary_fn = os.path.join(backbone_dir, 'self_consistency/esm_eval_results.csv')
            else:
                assert 'AlphaFold2' in self._forward_folding
                summary_fn = os.path.join(backbone_dir, 'self_consistency/af2_eval_results.csv')
            if os.path.exists(summary_fn):
                self._log.warning(f'Backbone {backbone_name} results already exists. Continuing...')

                continue
            
            os.makedirs(backbone_dir, exist_ok=True)
            self._log.info(f'Running self-consistency on {backbone_name}')
            print(f'pdb_file:{pdb_file}')
            print(f'backbone_dir:{backbone_dir}')
            shutil.copy2(os.path.join(self._sample_dir, pdb_file), backbone_dir)
            self._log.info(f'copied {pdb_file} to {backbone_dir}')
            
            #seperate_pdb_folder = os.path.join(backbone_dir, backbone_name)
            pdb_path = os.path.join(backbone_dir, pdb_file)
            sc_output_dir = os.path.join(backbone_dir, 'self_consistency')
            os.makedirs(sc_output_dir, exist_ok=True)
            shutil.copy(pdb_path, os.path.join(
                sc_output_dir, os.path.basename(pdb_path)))

            _ = self.run_self_consistency(
                decoy_pdb_dir=sc_output_dir,
                reference_pdb_path=pdb_path,
                motif_mask=None
            )
            self._log.info(f'Done sample: {pdb_path}')
    
    def run_self_consistency(
            self,
            decoy_pdb_dir: str,
            reference_pdb_path: str,
            motif_mask: Optional[np.ndarray]=None):
        """Run self-consistency on design proteins against reference protein.
        
        Args:
            decoy_pdb_dir: directory where designed protein files are stored.
            reference_pdb_path: path to reference protein file
            motif_mask: Optional mask of which residues are the motif.

        Returns:
            Writes ProteinMPNN outputs to decoy_pdb_dir/seqs
            Writes ESMFold outputs to decoy_pdb_dir/esmf
            Writes results in decoy_pdb_dir/sc_results.csv
        """

        # Run ProteinMPNN
        
        jsonl_path = os.path.join(decoy_pdb_dir, "parsed_pdbs.jsonl")
        process = subprocess.Popen([
            'python',
            f'{self._pmpnn_dir}/helper_scripts/parse_multiple_chains.py',
            f'--input_path={decoy_pdb_dir}',
            f'--output_path={jsonl_path}',
        ])
        
        _ = process.wait()
        num_tries = 0
        ret = -1
        pmpnn_args = [
            sys.executable,
            f'{self._pmpnn_dir}/protein_mpnn_run.py',
            '--out_folder',
            decoy_pdb_dir,
            '--jsonl_path',
            jsonl_path,
            '--num_seq_per_target',
            str(self._sample_conf.seq_per_sample),
            '--sampling_temp',
            '0.1',
            '--seed',
            '33',
            '--batch_size',
            str(self._sample_conf.mpnn_batch_size),
        ]
        self._log.info(f'Running ProteinMPNN with command {" ".join(pmpnn_args)}')
        if self._infer_conf.gpu_id is not None:
            pmpnn_args.append('--device')
            pmpnn_args.append(str(self._infer_conf.gpu_id))
        if self._CA_only == True:
            pmpnn_args.append('--ca_only')
        
        while ret < 0:
            try:
                print("Running ProteinMPNN...")
                # Setting CUDA_VISIBLE_DEVICES to an empty string to hide all GPUs
                env = os.environ.copy()
                if self._hide_GPU_from_pmpnn:
                    env["CUDA_VISIBLE_DEVICES"] = ""
                process = subprocess.Popen(
                    pmpnn_args,
                    env=env,
                    stdout=subprocess.DEVNULL,
                    stderr=subprocess.STDOUT
                )
                ret = process.wait()
            except Exception as e:
                num_tries += 1
                self._log.info(f'Failed ProteinMPNN. Attempt {num_tries}/5')
                torch.cuda.empty_cache()
                if num_tries > 4:
                    raise e
        mpnn_fasta_path = os.path.join(
            decoy_pdb_dir,
            'seqs',
            os.path.basename(reference_pdb_path).replace('.pdb', '.fa')
        )

        # Run ESMFold on each ProteinMPNN sequence and calculate metrics.
        mpnn_results = {
            'tm_score': [],
            'sample_path': [],
            'header': [],
            'sequence': [],
            'rmsd': [],
            'pae': [],
            'ptm': [],
            'plddt': [],
            'length': [],
            'mpnn_score': [],
            'sample_idx': []
        }
        if motif_mask is not None:
            # Only calculate motif RMSD if mask is specified.
            mpnn_results['refold_motif_rmsd'] = []
        esmf_dir = os.path.join(decoy_pdb_dir, 'esmf')
        af2_raw_dir = os.path.join(decoy_pdb_dir, 'af2_raw_outputs')
        fasta_seqs = fasta.FastaFile.read(mpnn_fasta_path)
        filtered_seqs = {header: seq for header, seq in fasta_seqs.items() if header.startswith("T=0")} # Drop original sequence
        if self._sample_conf.sort_by_score:
        # Only take seqs with lowerst global score to enter refolding
            scores = []
            for i, (header, string) in enumerate(filtered_seqs.items()):
                #if i == 0:
                #    global_score = float(header.split(", ")[2].split("=")[1])
                #    original_seq = (global_score, header, string)
                #else:
                global_score = float(header.split(", ")[3].split("=")[1])
                scores.append((global_score, header, string))
            scores.sort(key=lambda x: x[0])

            top_seqs_list = scores[:self._sample_conf.seq_per_sample]
            #top_seqs_list.insert(0, original_seq) # Include the original seq
            top_seqs = {header: seq for _, header, seq in top_seqs_list}

            top_seqs_path = os.path.join(
                decoy_pdb_dir,
                'seqs',
                f'top_score_{os.path.basename(reference_pdb_path)}'.replace('.pdb', '.fa')
            )
            print(f'top seqs: {top_seqs}\ntype: {type(top_seqs)}\n')
            _ = au.write_seqs_to_fasta(top_seqs, top_seqs_path)
        else:
            filtered_seqs = {header: seq for header, seq in fasta_seqs.items() if header.startswith("T=0")}
            #print(f'filtered_seqs: {filtered_seqs}')
            _ = au.write_seqs_to_fasta(filtered_seqs, mpnn_fasta_path)
        
        seqs_to_refold = top_seqs_path if self._sample_conf.sort_by_score else mpnn_fasta_path
        seqs_dict = fasta.FastaFile.read(seqs_to_refold)
        

        sample_feats = su.parse_pdb_feats('sample', reference_pdb_path)

        if 'ESMFold' in self._forward_folding:
            os.makedirs(esmf_dir, exist_ok=True)
            for i, (header, string) in enumerate(seqs_dict.items()):
                
                # Get score for ProteinMPNN
                if header.startswith("T=0"):
                    idx = header.split('sample=')[1].split(',')[0]
                    score = float(header.split(", ")[3].split("=")[1])
                else:
                    idx = 0
                    score = float(header.split(", ")[2].split("=")[1])
                # Run ESMFold
                self._log.info(f'Running ESMFold......')
                esmf_sample_path = os.path.join(esmf_dir, f'sample_{idx}.pdb')
                _, full_output = self.run_esmfold(string, esmf_sample_path)
                esmf_feats = su.parse_pdb_feats('folded_sample', esmf_sample_path)
                sample_seq = su.aatype_to_seq(sample_feats['aatype'])

                # Calculate scTM of ESMFold outputs with reference protein
                _, tm_score = su.calc_tm_score(
                    sample_feats['bb_positions'], esmf_feats['bb_positions'],
                    sample_seq, sample_seq)
                rmsd = su.calc_aligned_rmsd(
                    sample_feats['bb_positions'], esmf_feats['bb_positions'])
                pae = torch.mean(full_output['predicted_aligned_error']).item()
                ptm = full_output['ptm'].item()
                plddt = full_output['mean_plddt'].item()
                if motif_mask is not None:
                    sample_motif = sample_feats['bb_positions'][motif_mask]
                    esm_motif = esmf_feats['bb_positions'][motif_mask]
                    refold_motif_rmsd = su.calc_aligned_rmsd(
                        sample_motif, esm_motif)
                    mpnn_results['refold_motif_rmsd'].append(f'{refold_motif_rmsd:.3f}')
                mpnn_results['sample_idx'].append(int(idx))
                mpnn_results['rmsd'].append(f'{rmsd:.3f}')
                mpnn_results['tm_score'].append(f'{tm_score:.3f}')
                mpnn_results['sample_path'].append(os.path.abspath(esmf_sample_path))
                mpnn_results['header'].append(header)
                mpnn_results['sequence'].append(string)
                mpnn_results['pae'].append(f'{pae:.3f}')
                mpnn_results['ptm'].append(f'{ptm:.3f}')
                mpnn_results['plddt'].append(f'{plddt:.3f}')
                mpnn_results['length'].append(len(string))
                mpnn_results['mpnn_score'].append(f'{score:.3f}')

            # Save results to CSV
            esm_csv_path = os.path.join(decoy_pdb_dir, 'esm_eval_results.csv')
            mpnn_results = pd.DataFrame(mpnn_results)
            mpnn_results.sort_values('sample_idx', inplace=True)
            mpnn_results.to_csv(esm_csv_path, index=False)

        # Run AlphaFold2 (No MSA)
        if 'AlphaFold2' in self._forward_folding:
            self._log.info(f'Running AlphaFold2......')

            _ = self.run_af2(seqs_to_refold, af2_raw_dir)
            af2_dir = os.path.join(decoy_pdb_dir, 'af2')
            os.makedirs(af2_dir, exist_ok=True)
            af2_outputs = au.cleanup_af2_outputs(
                raw_dir=af2_raw_dir,
                clean_dir=os.path.join(decoy_pdb_dir, 'af2'),
                remove_after_cleanup=self._af2_conf.remove_raw_outputs
            )

            for i, (header, string) in enumerate(seqs_dict.items()):
                # Find index and score
                if header.startswith("T=0"):
                    idx = header.split('sample=')[1].split(',')[0]
                    score = float(header.split(", ")[3].split("=")[1])
                else:
                    idx = 0
                    score = float(header.split(", ")[2].split("=")[1])

                af2_sample_path = os.path.join(af2_dir, f'sample_{idx}.pdb')
                af2_feats = su.parse_pdb_feats('folded_sample', af2_sample_path)
                sample_seq = su.aatype_to_seq(sample_feats['aatype'])

                # Calculation
                _, tm_score = su.calc_tm_score(
                    sample_feats['bb_positions'], af2_feats['bb_positions'],
                    sample_seq, sample_seq)
                rmsd = su.calc_aligned_rmsd(
                    sample_feats['bb_positions'], af2_feats['bb_positions'])
                if motif_mask is not None:
                    sample_motif = sample_feats['bb_positions'][motif_mask]
                    af2_motif = af2_feats['bb_positions'][motif_mask]
                    refold_motif_rmsd = su.calc_aligned_rmsd(
                        sample_motif, af2_motif)
                    af2_outputs[f'sample_{idx}']['refold_motif_rmsd'] = f'{refold_motif_rmsd:.3f}'
                af2_outputs[f'sample_{idx}']['rmsd'] = f'{rmsd:.3f}'
                af2_outputs[f'sample_{idx}']['tm_score'] = f'{tm_score:.3f}'
                af2_outputs[f'sample_{idx}']['header'] = header
                af2_outputs[f'sample_{idx}']['sequence'] = string
                af2_outputs[f'sample_{idx}']['length'] = len(string)
                af2_outputs[f'sample_{idx}']['mpnn_score'] = f'{score:.3f}'
                af2_outputs[f'sample_{idx}']['sample_idx'] = int(idx)
            print(f'final_outputs: {af2_outputs}')
            af2_csv_path = os.path.join(decoy_pdb_dir, 'af2_eval_results.csv')
            af2_df = pd.DataFrame.from_dict(af2_outputs, orient='index')
            af2_df.reset_index(inplace=True)
            af2_df.rename(columns={'index': 'sample'}, inplace=True)
            af2_df.drop('sample', axis=1, inplace=True)
            af2_df.sort_values('sample_idx', inplace=True)
            af2_df.to_csv(af2_csv_path, index=False)

        if 'ESMFold' in self._forward_folding and 'AlphaFold2' in self._forward_folding:
            esm_results = pd.read_csv(esm_csv_path)
            af2_results = pd.read_csv(af2_csv_path)
            esm_results['folding_method'] = 'ESMFold'
            af2_results['folding_method'] = 'AlphaFold2'
            joint_results = pd.concat([esm_results, af2_results], ignore_index=True)
            joint_results.to_csv(os.path.join(decoy_pdb_dir, 'joint_eval_results.csv'), index=False)


    def run_esmfold(self, sequence: str, save_path: Union[str, Path]):
        """
        Run ESMFold on sequence.
        TBD: Add options for OmegaFold and AlphaFold2.
        """
        with torch.no_grad():
            output = self._folding_model.infer(sequence)
            output_dict = {key: value.cpu() for key, value in output.items()}
            output = self._folding_model.output_to_pdb(output)
        with open(save_path, "w") as f:
            f.write(output[0])
        return output, output_dict  

    def run_af2(self, sequence: str, save_path: Union[str, Path]):
        """
        Run AlphaFold2 (single-sequence) through LocalColabFold.
        """

        #_ = process.wait()
        num_tries_af2 = 0
        ret_af2 = -1

        # Setting AF2 args
        af2_args = [
            #sys.executable,
            'colabfold_batch',
            sequence,
            save_path,
            '--msa-mode',
            'single_sequence',
            '--num-recycle',
            str(self._af2_conf.recycle),
            '--random-seed',
            str(self._af2_conf.seed),
            '--model-type',
            self._af2_conf.model_type,
            '--num-models',
            str(self._af2_conf.num_models),
        ]
        if self._af2_conf.num_models > 1:
            af2_args.append('--rank')
            af2_args.append(self._af2_conf.rank)
        if self._af2_conf.use_amber_relax:
            af2_args.append('--amber')
            af2_args.append('--num-relax')
            af2_args.append(str(self._af2_conf.num_relax))
            if self._af2_conf.use_gpu_relax:
                af2_args.append('--use-gpu-relax')

        # Run AF2
        while ret_af2 < 0:
            try:
                process_af2 = subprocess.Popen(
                    af2_args,
                    stdout=subprocess.DEVNULL,
                    stderr=subprocess.STDOUT
                )
                
                ret_af2 = process_af2.wait()
            except Exception as e:
                num_tries_af2 += 1
                self._log.info(f'Hmm...Maybe some error occurs during executing AlphaFold2. Tried {num_tries_af2}/5')
                torch.cuda.empty_cache()
                if num_tries_af2 > 10:
                    raise e


class UnconditionalEvaluator:
    
    def __init__(
        self, 
        conf:DictConfig,
        conf_overrides: Dict=None
        ):

        self._log = logging.getLogger(self.__class__.__name__)
        logging.getLogger("matplotlib.font_manager").setLevel(logging.ERROR)

        OmegaConf.set_struct(conf, False)

        self._conf = conf
        self._infer_conf = conf.inference
        self._eval_conf = conf.evaluation
        self._result_dir = self._infer_conf.output_dir

        self._package_dir = "/".join(scaffold_lab.__path__._path[0].split("/")[:-1])
        self._assist_protein_path = os.path.join(self._package_dir, self._eval_conf.assist_protein)
        self._tm_threshold = self._eval_conf.tmscore_threshold
        self._visualize = self._eval_conf.visualize

        self.folding_method = self._infer_conf.predict_method

        self._rng = np.random.default_rng(self._infer_conf.seed)

        # Merge results into one csv file
        if 'ESMFold' in self.folding_method and 'AlphaFold2' in self.folding_method:
            self.prefix = 'joint'
        elif 'ESMFold' in self.folding_method and 'AlphaFold2' not in self.folding_method:
            self.prefix = 'esm'
        else:
            self.prefix = 'af2'


    def _process_results(self, prefix: str):
        """Process results for a single forward folding method (ESMFold / AF2)."""
        results_df, pdb_count = au.csv_merge(root_dir=self._result_dir, prefix=prefix)

        # Analyze outputs
        complete_results, summary_results, designability_count, backbones, best_contender = au.analyze_success_rate_uncond(
            merged_data=results_df, group_mode="all", prefix=prefix
        )

        summary_csv_path = os.path.join(self._result_dir, f"{prefix}_summary_results.csv")
        complete_csv_path = os.path.join(self._result_dir, f"{prefix}_complete_results.csv")
        complete_results.to_csv(complete_csv_path, index=False)
        summary_column_order = [
            "sample_idx",
            "Success",
            "rmsd",
            "length",
            "sequence",
            "sample_path",
            "backbone_path",
        ]
        summary_results.to_csv(summary_csv_path, columns=summary_column_order, index=False)

        # Auxiliary metrics
        if not best_contender is None:
            best_scaffold_dir = os.path.join(self._result_dir, f"{prefix}_best_contender")
            os.makedirs(best_scaffold_dir, exist_ok=True)
            
            best_contender_csv_path = os.path.join(best_scaffold_dir, f"{prefix}_best_contender.csv")
            best_contender.to_csv(best_contender_csv_path, index=False)
            
            best_contender_path = best_contender['backbone_path'].iloc[0]
            shutil.copy(best_contender_path, os.path.join(best_scaffold_dir, os.path.basename(best_contender_path)))

        return complete_results, backbones, designability_count, pdb_count, best_contender


    def _collect_successful_backbones(
        self, 
        backbones: set, 
        prefix: str
        ):
        """Collect successful backbones without Foldseek clustering."""
        successful_backbone_dir = os.path.join(self._result_dir, f"{prefix}_successful_backbones")
        os.makedirs(successful_backbone_dir, exist_ok=True)

        for pdb in backbones:
            shutil.copy(pdb, os.path.join(successful_backbone_dir, os.path.basename(pdb)))

        self._log.info(
            f"Collected {len(backbones)} successful backbones for {prefix}."
        )

        return successful_backbone_dir


    def run_evaluation(self):
        """Run evaluation for all specified folding methods (without Foldseek)."""
        designability_counts = {}
        pdb_counts = {}

        for method in self.folding_method:
            self._log.info(f"Processing results for folding method: {method}")
            prefix = "esm" if method == "ESMFold" else "af2"

            # Process results
            complete_results, backbones, designability_count, pdb_count, best_contender = self._process_results(prefix)
            
            # Collect successful backbones (without Foldseek clustering)
            successful_backbone_dir = self._collect_successful_backbones(backbones, prefix)

            # Collect results
            designability_counts[prefix] = designability_count
            pdb_counts[prefix] = pdb_count

            # Auxiliary metrics
            au.write_auxiliary_metrics_uncond(
                stored_path=self._result_dir,
                auxiliary_results=best_contender,
                prefix=prefix
            )

        # Write summary outputs (without diversity and novelty)
        for prefix in designability_counts.keys():
            summary_path = os.path.join(self._result_dir, f"{prefix}_evaluation_summary.txt")
            with open(summary_path, 'w') as f:
                f.write(f"Evaluation Summary for {prefix}\n")
                f.write(f"="*50 + "\n")
                f.write(f"Total PDB count: {pdb_counts[prefix]}\n")
                f.write(f"Designable count: {designability_counts[prefix]}\n")
                f.write(f"Designability rate: {designability_counts[prefix]/pdb_counts[prefix]*100:.2f}%\n")
            self._log.info(f"Summary written to {summary_path}")

        # Optional visualization
        if self._visualize:
            for method in self.folding_method:
                self._log.info(f"Performing visualization for {method}.")
                prefix = "esm" if method == "ESMFold" else "af2"

                pu.unconditional_pymol_write(
                    unique_designable_backbones=os.path.join(self._result_dir, f'{prefix}_successful_backbones'),
                    save_path=os.path.join(self._result_dir, f'{prefix}_pymol_session.pse')
                    )

                # Auxiliary metrics
                best_contender_path = os.path.join(self._result_dir, f'{prefix}_best_contender')
                if os.path.exists(best_contender_path) and os.listdir(best_contender_path):
                    pu.unconditional_pymol_write(
                        unique_designable_backbones=best_contender_path,
                        save_path=os.path.join(best_contender_path, f'{prefix}_best_contender.pse')
                    )
                


@hydra.main(version_base=None, config_path="../../config",
        config_name="unconditional.yaml")
def run(conf: DictConfig) -> None:

    # Perform fixed backbone design and forward folding
    print("Starting refolding for unconditional task......")
    start_time = time.time()
    refolder = UnconditionalRefolder(conf)
    refolder.run_sampling()
    elapsed_time = time.time() - start_time
    print(f"Refolding finished in {elapsed_time:.2f}s.")

    # Perform analysis on outputs (without Foldseek)
    start_time = time.time()
    evaluator = UnconditionalEvaluator(conf)
    evaluator.run_evaluation()
    elapsed_time = time.time() - start_time
    print(f'Evaluation finished in {elapsed_time:.2f}s. Voila!')
    
if __name__ == '__main__':
    run()
