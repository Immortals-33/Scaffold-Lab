"""
Main script for refolding pipeline on motif-scaffolding task.
The refolding pipeline use ESMFold as default.

To run AlphaFold2:
> python scaffold_lab/motif_scaffolding/motif_refolding.py inference.predict_method='AlphaFold2'

To run ESMFold and AlphaFold2 simultaneously:
> python scaffold_lab/motif_scaffolding/motif_refolding.py inference.predict_method='[AlphaFold2, ESMFold]'

"""

import os
import tree
import time
import json
import numpy as np
import hydra
import torch
import subprocess
import re
import random
import logging
import warnings
import pandas as pd
import sys
import rootutils
import shutil
import GPUtil
from pathlib import Path
from typing import Optional, Dict, Union, List
from omegaconf import DictConfig, OmegaConf
from collections import defaultdict

import esm
import biotite.structure.io as strucio
from biotite.sequence.io import fasta


path = rootutils.find_root(search_from='./', indicator=[".git", "setup.cfg"])
rootutils.set_root(
    path=path, # path to the root directory
    project_root_env_var=True, # set the PROJECT_ROOT environment variable to root directory
    dotenv=True, # load environment variables from .env if exists in root directory
    pythonpath=True, # add root directory to the PYTHONPATH (helps with imports)
    cwd=True, # change current working directory to the root directory (helps with filepaths)
)

import scaffold_lab
from analysis import utils as au
from data import structure_utils as su
from analysis import diversity as du
from analysis import novelty as nu
from analysis import plot as pu


class MotifRefolder:

    """
    Perform refolding analysis on a set of protein backbones.
    Organized by the following steps:
    1. Config initialization
    2. Read motif information
    3. Run ProteinMPNN on a given set of PDB files
    4. Run ESMFold / AlphaFold2 on sequences generated by ProteinMPNN ()
    5. Calculate the metrics (RMSD, TM-score, motif-RMSD, pLDDT, etc.) and write information into a csv file.

    One can also modify this script to perform fixed backbone design and evaluations on refoldability.
    Adapted from https://github.com/jasonkyuyim/se3_diffusion/blob/master/experiments/inference_se3_diffusion.py
    """

    def __init__(
        self,
        conf:DictConfig,
        conf_overrides: Dict=None
        ):

        self._log = logging.getLogger(self.__class__.__name__)
        warnings.filterwarnings("ignore", module="biotite.*|psutil.*|matplotlib.*", category=UserWarning)

        OmegaConf.set_struct(conf, False)

        self._package_dir = "/".join(scaffold_lab.__path__._path[0].split("/")[:-1])
        self._conf = conf
        self._infer_conf = conf.inference
        self._sample_conf = self._infer_conf.samples

        # Sanity check
        if self._sample_conf.seq_per_sample < self._sample_conf.mpnn_batch_size:
            raise ValueError(f'Sequences per sample {self._sample_conf.seq_per_sample} < \
            batch size {self._sample_conf.mpnn_batch_size}!')

        self._rng = np.random.default_rng(self._infer_conf.seed)

        # Set-up accelerator
        if torch.cuda.is_available():
            if self._infer_conf.gpu_id is None:
                available_gpus = ''.join(
                    [str(x) for x in GPUtil.getAvailable(
                        order="memory", limit = 8)]
                )
                self.device = f'cuda:{available_gpus[0]}'
            else:
                self.device = f'cuda:{self._infer_conf.gpu_id}'
        else:
            self.device = 'cpu'
        self._log.info(f'Using device: {self.device}')

        # Customizing different structure prediction methods
        self._forward_folding = self._infer_conf.predict_method
        if 'AlphaFold2' in self._forward_folding:
            self._af2_conf = self._infer_conf.af2
            colabfold_path = self._af2_conf.executive_colabfold_path
            current_path = os.environ.get('PATH', '')
            os.environ['PATH'] = colabfold_path + ":" + current_path
            if self.device == 'cpu':
                self._log.info(f"You're running AlphaFold2 on {self.device}.")
        # Set-up directories
        output_dir = self._infer_conf.output_dir

        self._output_dir = output_dir
        os.makedirs(self._output_dir, exist_ok=True)
        self._pmpnn_dir = os.path.join(self._package_dir, self._infer_conf.pmpnn_dir)
        self._sample_dir = self._infer_conf.backbone_pdb_dir
        self._CA_only = self._infer_conf.CA_only
        self._hide_GPU_from_pmpnn = self._infer_conf.hide_GPU_from_pmpnn
        self._max_backbones = self._infer_conf.samples.max_backbones

        # Configs for motif-scaffolding
        if self._infer_conf.motif_csv_path is not None:
            self._motif_csv = self._infer_conf.motif_csv_path
        self._motif_pdb = self._infer_conf.motif_pdb
        self._whole_benchmark_set = None

        # Save config
        config_folder = os.path.basename(Path(self._output_dir))
        config_path = os.path.join(self._output_dir, f"{config_folder}.yaml")
        with open(config_path, 'w') as f:
            OmegaConf.save(config=self._conf, f=f)
        self._log.info(f'Saving self-consistency config to {config_path}')

        # Load models and experiment
        if 'cuda' in self.device:
            self._folding_model = esm.pretrained.esmfold_v1().eval()
        elif self.device == 'cpu': # ESMFold is not supported for half-precision model when running on CPU
            self._folding_model = esm.pretrained.esmfold_v1().float().eval()
        self._folding_model = self._folding_model.to(self.device)


    def run_sampling(self):
        
        # Run ProteinMPNN
        motif_info_dict = {}

        for pdb_file in os.listdir(self._sample_dir):

            naming_number = 1

            if ".pdb" not in pdb_file:
                continue

            # Backbone name handling
            all_name = os.path.splitext(pdb_file)[0]
            design_pdb = os.path.join(self._sample_dir, pdb_file)
            try:
                case_num, backbone_name, sample_num = all_name.split("_") # "01_1BCF_1.pdb"
                if self._max_backbones and int(sample_num) >= self._max_backbones:
                    self._log.info(f"Skipping sample {sample_num} because "
                            f"max_backbones={self._max_backbones}")
                    continue

                
                backbone_name = case_num + "_" + backbone_name
                self._log.info(f"case_num: {case_num}, tested case: {backbone_name}, sample_num: {sample_num}")
                reference_pdb = os.path.join(self._motif_pdb)
            except ValueError:
                self._log.warning(f"The naming format {all_name} is not as default. \
                Try to use another format.")
                try:
                    assert len(all_name.split("_")) == 2, f"{all_name} not following default!"
                    backbone_name, sample_num = all_name.split("_") # "1BCF_1.pdb"
                    self._log.info(f"tested case :{backbone_name}, sample_num: {sample_num}")
                    reference_pdb = self._motif_pdb
                except (ValueError, AssertionError):
                    self._log.warning(f"The naming format {all_name} is not as default. \
                    Try to rename the PDB file to format.")
                    for native_pdb in self._whole_benchmark_set:
                        print(f"native_pdb: {native_pdb}")
                        if native_pdb in all_name.upper():
                            print(f"all name upper: {all_name.upper()}")
                            backbone_name = native_pdb
                            break
                        else:
                            raise ValueError(f"No benchmark case detected in {all_name}. Try to reformat.")
                    reference_pdb = self._motif_pdb
                    rename_design_pdb = os.path.join(self._output_dir, f"{backbone_name}_{naming_number}.pdb")
                    shutil.copy2(design_pdb, rename_design_pdb)
                    design_pdb = rename_design_pdb
                    naming_number += 1


            # The following part is a test version and needed to be cleaned up.
            if self._whole_benchmark_set is not None:
                try:
                    benchmark_set_info = pd.read_csv(self._whole_benchmark_set)
                    reference_contig = benchmark_set_info.iloc[
                        benchmark_set_info.iloc[:, 0] == backbone_name, 1
                    ].values[0]

                    #motif_pdb = os.path.join(, f"{backbone_name}.pdb")
                    reference_motif = au.motif_extract(reference_contig, reference_pdb, atom_part="backbone")
                except FileNotFoundError:
                    raise FileNotFoundError(f"Benchmark Information not found in {benchmark_set_info}.")
                except IndexError:
                    raise ValueError(f"No contig value found for the name {backbone_name} in benchmark information.")
                except Exception as e:
                    pass
                    #raise RuntimeError(f"An error occured while processing {pdb_file}.")
                

            # Read motif information data and save into json file
            if os.path.exists(self._motif_csv):
                csv_data = au.get_csv_data(self._motif_csv, backbone_name, sample_num)
            else:
                csv_data = au.parse_input_scaffold(
                    os.path.join(self._sample_dir, pdb_file))

            if csv_data == None:
                self._log.warning(f'Motif information is missing for {pdb_file}. Skipping...')
                continue
            contig, mask, motif_indices, redesign_info, segments_order = csv_data

            # Directly extract contig from motif_pdb files
            reference_contig = au.reference_contig_from_segments(reference_pdb, segments_order)
            # The contig in designed pdb files
            design_contig = au.motif_indices_to_contig(motif_indices)

            
            # Store information for later pymol visualization
            motif_info_dict[f'{backbone_name}_{sample_num}'] = {
                "contig": reference_contig,
                "motif_idx": motif_indices,
                "redesign_info": redesign_info
            }
            
            # Save outputs
            backbone_dir = os.path.join(self._output_dir, f'{backbone_name}_{sample_num}')
            if "ESMFold" in self._forward_folding:
                summary_fn = os.path.join(backbone_dir, 'self_consistency/esm_eval_results.csv')
            else:
                assert 'AlphaFold2' in self._forward_folding
                summary_fn = os.path.join(backbone_dir, 'self_consistency/af2_eval_results.csv')
            if os.path.exists(summary_fn):
                self._log.warning(f'Backbone {backbone_name}_{sample_num} results already exists. Continuing...')
                continue

            os.makedirs(backbone_dir, exist_ok=True)
            self._log.info(f'Running self-consistency on {backbone_name}, '
                    f'sample {sample_num}')
            shutil.copy2(os.path.join(self._sample_dir, pdb_file), backbone_dir)
            print(f'copied {pdb_file} to {backbone_dir}')

            
            # Handle redesigned positions
            self._log.info(f'Positions allowed to be redesigned: {redesign_info}')

            if redesign_info is not None:
                self._log.info(f'Positions allowed to be redesigned: {redesign_info}')
            else:
                self._log.info(f'No positions need to be redesigned.')
            # Will return standard mapping list and fixed positions if no residue within motifs need to be redesigned
            redesign_mapping_dict, redesign_position_list, fixed_idx_for_mpnn = au.motif_mapping(
                motif_indices=motif_indices, 
                redesign_positions=redesign_info, 
                contig=contig
                )
                
            if self._infer_conf.force_motif_AA_type:
                modified_design_pdb_path = os.path.join(backbone_dir, f"{backbone_name}_{sample_num}.pdb")
                
                # This will overwrite original protein if AA types of motifs are not all correct.
                # The original pdb will be copied to another directory named "original_pdb" as a reference.
                motif_AA_correct = au.check_motif_AA_type(
                    design_file=design_pdb,
                    reference_file=reference_pdb,
                    position_mapping=redesign_mapping_dict,
                    redesign_list=redesign_position_list,
                    output_file=modified_design_pdb_path
                )
                if motif_AA_correct == False:
                    original_pdb_dir = os.path.join(backbone_dir, "original_pdb")
                    os.makedirs(original_pdb_dir, exist_ok=True)
                    shutil.copy2(design_pdb, original_pdb_dir)
                    self._log.info(f"Copied original PDB to {original_pdb_dir} as reference.")
                    design_pdb = modified_design_pdb_path   

            # Extract motif and calculate backbone motif-RMSD, which is the `backbone_motif_rmsd` metric in outputs.
            # !!Note: This `rms` is the motif-RMSD between native motif and initially-generated backbone,
            # i.e. without refolding procedure.
            reference_motif_CA = au.motif_extract(reference_contig,
                    reference_pdb, atom_part="CA")
            design_motif_CA = au.motif_extract(design_contig, design_pdb,
                    atom_part="CA")
            backbone_motif_rmsd = au.rmsd(reference_motif_CA, design_motif_CA)

            # Extract motif with all backbone atoms for subsequent
            # motif_rmsd computation on predicted folded structure.
            design_motif = au.motif_extract(design_contig, design_pdb, atom_part="backbone")
            reference_motif = au.motif_extract(reference_contig, reference_pdb, atom_part="backbone")


            if self._infer_conf.force_motif_AA_type and motif_AA_correct == False:
                pdb_path = modified_design_pdb_path
            else:
                pdb_path = os.path.join(backbone_dir, pdb_file)

            sc_output_dir = os.path.join(backbone_dir, 'self_consistency')
            os.makedirs(sc_output_dir, exist_ok=True)
            shutil.copy(pdb_path, os.path.join(
                sc_output_dir, os.path.basename(pdb_path)))


            if backbone_name == '6VW1':
                _ = self.run_self_consistency(
                decoy_pdb_dir=sc_output_dir,
                reference_pdb_path=pdb_path,
                motif_mask=mask,
                fixed_indices=fixed_idx_for_mpnn,
                backbone_motif_rmsd=backbone_motif_rmsd,
                #complex_motif=chain_B_indices
            )

            else:
                _ = self.run_self_consistency(
                    decoy_pdb_dir=sc_output_dir,
                    reference_pdb_path=pdb_path,
                    motif_mask=mask,
                    fixed_indices=fixed_idx_for_mpnn,
                    backbone_motif_rmsd=backbone_motif_rmsd,
                    ref_motif=reference_motif,
                    sample_contig=design_contig
                )
            self._log.info(f'Done sample: {pdb_path}')
        output_json_path = os.path.join(self._output_dir, 'motif_info.json')
        with open(output_json_path, 'w') as json_file:
            json.dump(motif_info_dict, json_file, indent=4, separators=(",", ": "), sort_keys=True)
        self._log.info(f'Motif information saved into {output_json_path}')


    def run_self_consistency(
            self,
            decoy_pdb_dir: str,
            reference_pdb_path: str,
            motif_mask: Optional[np.ndarray]=None,
            fixed_indices: Optional[Union[List, str]]=None,
            backbone_motif_rmsd: Optional[float]=None,
            complex_motif: Optional[List]=None,
            ref_motif=None,
            sample_contig=None
            ):
        """Run self-consistency on design proteins against reference protein.

        Args:
            decoy_pdb_dir: directory where designed protein files are stored.
            reference_pdb_path: path to reference protein file
            motif_mask: Optional mask of which residues are the motif.
            fixed_indices: Optionial list-like object indicating which positions are allowed to be redesigned.
            backbone_motif_rmsd: The Motif-RMSD between the motifs of designed generated backbones (without refold) and native motifs.
            complex_motif: (TBD) Add features for complex motif calculation.
            ref_motif: Motif 3D corrdinates of native PDBs. Represented by backbone atoms.
            sample_contig: The contig indicating the motif locations on designed backbones to calculating Motif-RMSD.

        Returns:
            Writes ProteinMPNN outputs to decoy_pdb_dir/seqs
            Writes ESMFold outputs to decoy_pdb_dir/esmf
            Writes results in decoy_pdb_dir/sc_results.csv
        """

        # Check whether given backbones are CA-only
        file_to_be_checked = os.path.join(
            decoy_pdb_dir,
            random.choice([f for f in os.listdir(decoy_pdb_dir) if f.endswith('.pdb')]))
        checked_structure = strucio.load_structure(file_to_be_checked)
        # Assume all backbones with atom types <= 3 to be used with CA-only-ProteinMPNN
        if len(set(checked_structure.atom_name)) <= 3:
            self._log.warning(f'The input protein only has atom type(s): {set(checked_structure.atom_name)}\n\
            Deprecating ProteinMPNN to CA-only version.')
            self._CA_only = True
        else:
            self._log.info(f'The input protein has atom types: {set(checked_structure.atom_name)}\n\
            Recommend using full-backbone version of ProteinMPNN.')
            pass


        # Run ProteinMPNN

        jsonl_path = os.path.join(decoy_pdb_dir, "parsed_pdbs.jsonl")
        process = subprocess.Popen([
            'python',
            f'{self._pmpnn_dir}/helper_scripts/parse_multiple_chains.py',
            f'--input_path={decoy_pdb_dir}',
            f'--output_path={jsonl_path}',
        ])

        _ = process.wait()
        num_tries = 0
        ret = -1
        pmpnn_args = [
            sys.executable,
            f'{self._pmpnn_dir}/protein_mpnn_run.py',
            '--out_folder',
            decoy_pdb_dir,
            '--jsonl_path',
            jsonl_path,
            '--num_seq_per_target',
            str(self._sample_conf.seq_per_sample),
            '--sampling_temp',
            '0.1',
            '--seed',
            '33',
            '--batch_size',
            str(self._sample_conf.mpnn_batch_size),
        ]
        self._log.info(f'Running ProteinMPNN with command {" ".join(pmpnn_args)}')
        if self._infer_conf.gpu_id is not None:
            pmpnn_args.append('--device')
            pmpnn_args.append(str(self._infer_conf.gpu_id))
        if self._CA_only == True:
            pmpnn_args.append('--ca_only')

        # Fix desired motifs
        if (fixed_indices is not None) and (len(fixed_indices) !=0):
            fixed_positions = au.motif_indices_to_fixed_positions(fixed_indices)
            print(f"fix positions: {fixed_positions}")
            chains_to_design = "A"
            # This is particularlly for 6VW1
            if complex_motif is not None:
                fixed_indices = fixed_indices.strip('[]').split(', ')
                fixed_indices = sorted([int(index) for index in fixed_indices])
                fixed_indices = [element for element in fixed_indices if element not in complex_motif]
                complex_motif = " ".join(map(str, complex_motif)) # List2str
                fixed_positions = " ".join(map(str, fixed_indices)) # List2str
                fixed_positions = fixed_positions + ", " + complex_motif
                chains_to_design = "A B"
            path_for_fixed_positions = os.path.join(decoy_pdb_dir, "fixed_pdbs.jsonl")


            subprocess.call([
                'python',
                os.path.join(self._pmpnn_dir, 'helper_scripts/make_fixed_positions_dict.py'),
                '--input_path', jsonl_path,
                '--output_path', path_for_fixed_positions,
                '--chain_list', chains_to_design,
                '--position_list', fixed_positions
            ])

            pmpnn_args.extend([
                '--chain_id_jsonl', os.path.join(decoy_pdb_dir, "assigned_pdbs.jsonl"),
                '--fixed_positions_jsonl', path_for_fixed_positions
            ])

        while ret < 0:
            try:
                print("Running ProteinMPNN...")
                # Setting CUDA_VISIBLE_DEVICES to an empty string to hide all GPUs
                env = os.environ.copy()
                if self._hide_GPU_from_pmpnn:
                    env["CUDA_VISIBLE_DEVICES"] = ""
                process = subprocess.Popen(
                    pmpnn_args,
                    env=env,
                    stdout=subprocess.DEVNULL,
                    stderr=subprocess.STDOUT
                )
                ret = process.wait()
            except Exception as e:
                num_tries += 1
                self._log.info(f'Failed ProteinMPNN. Attempt {num_tries}/5')
                torch.cuda.empty_cache()
                if num_tries > 4:
                    raise e
        mpnn_fasta_path = os.path.join(
            decoy_pdb_dir,
            'seqs',
            os.path.basename(reference_pdb_path).replace('.pdb', '.fa')
        )

        # Run ESMFold on each ProteinMPNN sequence and calculate metrics.
        mpnn_results = {
            'tm_score': [],
            'sample_path': [],
            'header': [],
            'sequence': [],
            'rmsd': [],
            'pae': [],
            'ptm': [],
            'plddt': [],
            'length': [],
            'backbone_motif_rmsd': [],
            'motif_rmsd': [],
            'mpnn_score': [],
            'sample_idx': []
        }
        if motif_mask is not None:
            # Only calculate motif RMSD if mask is specified.
            mpnn_results['refold_motif_rmsd'] = []
        esmf_dir = os.path.join(decoy_pdb_dir, 'esmf')
        af2_raw_dir = os.path.join(decoy_pdb_dir, 'af2_raw_outputs')
        fasta_seqs = fasta.FastaFile.read(mpnn_fasta_path)
        filtered_seqs = {header: seq for header, seq in fasta_seqs.items() if header.startswith("T=0")} # Drop original sequence
        if self._sample_conf.sort_by_score:
        # Only take seqs with lowerst global score to enter refolding
            scores = []
            for i, (header, string) in enumerate(filtered_seqs.items()):
                #if i == 0:
                #    global_score = float(header.split(", ")[2].split("=")[1])
                #    original_seq = (global_score, header, string)
                #else:
                global_score = float(header.split(", ")[3].split("=")[1])
                scores.append((global_score, header, string))
            scores.sort(key=lambda x: x[0])

            top_seqs_list = scores[:self._sample_conf.seq_per_sample]
            #top_seqs_list.insert(0, original_seq) # Include the original seq
            top_seqs = {header: seq for _, header, seq in top_seqs_list}

            top_seqs_path = os.path.join(
                decoy_pdb_dir,
                'seqs',
                f'top_score_{os.path.basename(reference_pdb_path)}'.replace('.pdb', '.fa')
            )
            print(f'top seqs: {top_seqs}\ntype: {type(top_seqs)}\n')
            _ = au.write_seqs_to_fasta(top_seqs, top_seqs_path)
        else:
            filtered_seqs = {header: seq for header, seq in fasta_seqs.items() if header.startswith("T=0")}
            #print(f'filtered_seqs: {filtered_seqs}')
            _ = au.write_seqs_to_fasta(filtered_seqs, mpnn_fasta_path)

        seqs_to_refold = top_seqs_path if self._sample_conf.sort_by_score else mpnn_fasta_path
        seqs_dict = fasta.FastaFile.read(seqs_to_refold)


        sample_feats = su.parse_pdb_feats('sample', reference_pdb_path)

        if 'ESMFold' in self._forward_folding:
            os.makedirs(esmf_dir, exist_ok=True)
            for i, (header, string) in enumerate(seqs_dict.items()):

                # Get score for ProteinMPNN
                if header.startswith("T=0"):
                    idx = header.split('sample=')[1].split(',')[0]
                    score = float(header.split(", ")[3].split("=")[1])
                else:
                    idx = 0
                    score = float(header.split(", ")[2].split("=")[1])
            # Run ESMFold
                self._log.info(f'Running ESMFold......')
                esmf_sample_path = os.path.join(esmf_dir, f'sample_{idx}.pdb')
                _, full_output = self.run_esmfold(string, esmf_sample_path)
                esmf_feats = su.parse_pdb_feats('folded_sample', esmf_sample_path)
                sample_seq = su.aatype_to_seq(sample_feats['aatype'])

                esm_predict_motif = au.motif_extract(sample_contig, esmf_sample_path, atom_part="backbone")
                motif_rmsd = au.rmsd(ref_motif, esm_predict_motif)
                mpnn_results['motif_rmsd'].append(f'{motif_rmsd:.3f}')
                # Calculate scTM of ESMFold outputs with reference protein
                _, tm_score = su.calc_tm_score(
                    sample_feats['bb_positions'], esmf_feats['bb_positions'],
                    sample_seq, sample_seq)
                rmsd = su.calc_aligned_rmsd(
                    sample_feats['bb_positions'], esmf_feats['bb_positions'])
                pae = torch.mean(full_output['predicted_aligned_error']).item()
                ptm = full_output['ptm'].item()
                plddt = full_output['mean_plddt'].item()
                if motif_mask is not None:
                    sample_motif = sample_feats['bb_positions'][motif_mask]
                    esm_motif = esmf_feats['bb_positions'][motif_mask]
                    refold_motif_rmsd = su.calc_aligned_rmsd(
                        sample_motif, esm_motif)
                    mpnn_results['refold_motif_rmsd'].append(f'{refold_motif_rmsd:.3f}')
                if backbone_motif_rmsd is not None:
                    mpnn_results['backbone_motif_rmsd'].append(f'{backbone_motif_rmsd:.3f}')
                mpnn_results['sample_idx'].append(int(idx))
                mpnn_results['rmsd'].append(f'{rmsd:.3f}')
                mpnn_results['tm_score'].append(f'{tm_score:.3f}')
                mpnn_results['sample_path'].append(os.path.abspath(esmf_sample_path))
                mpnn_results['header'].append(header)
                mpnn_results['sequence'].append(string)
                mpnn_results['pae'].append(f'{pae:.3f}')
                mpnn_results['ptm'].append(f'{ptm:.3f}')
                mpnn_results['plddt'].append(f'{plddt:.3f}')
                mpnn_results['length'].append(len(string))
                mpnn_results['mpnn_score'].append(f'{score:.3f}')

            # Save results to CSV
            esm_csv_path = os.path.join(decoy_pdb_dir, 'esm_eval_results.csv')
            mpnn_results = pd.DataFrame(mpnn_results)
            mpnn_results.sort_values('sample_idx', inplace=True)
            mpnn_results.to_csv(esm_csv_path, index=False)

        # Run AlphaFold2 (No MSA)
        if 'AlphaFold2' in self._forward_folding:
            self._log.info(f'Running AlphaFold2......')

            _ = self.run_af2(seqs_to_refold, af2_raw_dir)
            af2_dir = os.path.join(decoy_pdb_dir, 'af2')
            os.makedirs(af2_dir, exist_ok=True)
            af2_outputs = au.cleanup_af2_outputs(
                raw_dir=af2_raw_dir,
                clean_dir=os.path.join(decoy_pdb_dir, 'af2'),
                remove_after_cleanup=self._af2_conf.remove_raw_outputs
            )

            for i, (header, string) in enumerate(seqs_dict.items()):
                # Find index and score
                if header.startswith("T=0"):
                    idx = header.split('sample=')[1].split(',')[0]
                    score = float(header.split(", ")[3].split("=")[1])
                else:
                    idx = 0
                    score = float(header.split(", ")[2].split("=")[1])

                af2_sample_path = os.path.join(af2_dir, f'sample_{idx}.pdb')
                af2_feats = su.parse_pdb_feats('folded_sample', af2_sample_path)
                sample_seq = su.aatype_to_seq(sample_feats['aatype'])

                af2_predict_motif = au.motif_extract(sample_contig, af2_sample_path, atom_part="backbone")
                motif_rmsd = au.rmsd(ref_motif, af2_predict_motif)
                af2_outputs[f'sample_{idx}']['motif_rmsd'] = f'{motif_rmsd:.3f}'


                # Calculation
                _, tm_score = su.calc_tm_score(
                    sample_feats['bb_positions'], af2_feats['bb_positions'],
                    sample_seq, sample_seq)
                rmsd = su.calc_aligned_rmsd(
                    sample_feats['bb_positions'], af2_feats['bb_positions'])
                if motif_mask is not None:
                    sample_motif = sample_feats['bb_positions'][motif_mask]
                    af2_motif = af2_feats['bb_positions'][motif_mask]
                    refold_motif_rmsd = su.calc_aligned_rmsd(
                        sample_motif, af2_motif)
                    af2_outputs[f'sample_{idx}']['refold_motif_rmsd'] = f'{refold_motif_rmsd:.3f}'
                if backbone_motif_rmsd is not None:
                    af2_outputs[f'sample_{idx}']['backbone_motif_rmsd'] = f'{backbone_motif_rmsd:.3f}'
                af2_outputs[f'sample_{idx}']['rmsd'] = f'{rmsd:.3f}'
                af2_outputs[f'sample_{idx}']['tm_score'] = f'{tm_score:.3f}'
                af2_outputs[f'sample_{idx}']['header'] = header
                af2_outputs[f'sample_{idx}']['sequence'] = string
                af2_outputs[f'sample_{idx}']['length'] = len(string)
                af2_outputs[f'sample_{idx}']['mpnn_score'] = f'{score:.3f}'
                af2_outputs[f'sample_{idx}']['sample_idx'] = int(idx)
            print(f'final_outputs: {af2_outputs}')
            af2_csv_path = os.path.join(decoy_pdb_dir, 'af2_eval_results.csv')
            af2_df = pd.DataFrame.from_dict(af2_outputs, orient='index')
            af2_df.reset_index(inplace=True)
            af2_df.rename(columns={'index': 'sample'}, inplace=True)
            af2_df.drop('sample', axis=1, inplace=True)
            af2_df.sort_values('sample_idx', inplace=True)
            af2_df.to_csv(af2_csv_path, index=False)

        if 'ESMFold' in self._forward_folding and 'AlphaFold2' in self._forward_folding:
            esm_results = pd.read_csv(esm_csv_path)
            af2_results = pd.read_csv(af2_csv_path)
            esm_results['folding_method'] = 'ESMFold'
            af2_results['folding_method'] = 'AlphaFold2'
            joint_results = pd.concat([esm_results, af2_results], ignore_index=True)
            joint_results.to_csv(os.path.join(decoy_pdb_dir, 'joint_eval_results.csv'), index=False)



    def run_esmfold(self, sequence: str, save_path: Union[str, Path]):
        """
        Run ESMFold on sequence.
        TBD: Add options for OmegaFold and AlphaFold2.
        """
        with torch.no_grad():
            output = self._folding_model.infer(sequence)
            output_dict = {key: value.cpu() for key, value in output.items()}
            output = self._folding_model.output_to_pdb(output)
        with open(save_path, "w") as f:
            f.write(output[0])
        return output, output_dict

    def run_af2(self, sequence: str, save_path: Union[str, Path]):
        """
        Run AlphaFold2 (single-sequence) through LocalColabFold.
        """

        #_ = process.wait()
        num_tries_af2 = 0
        ret_af2 = -1

        # Setting AF2 args
        af2_args = [
            #sys.executable,
            'colabfold_batch',
            sequence,
            save_path,
            '--msa-mode',
            'single_sequence',
            '--num-recycle',
            str(self._af2_conf.recycle),
            '--random-seed',
            str(self._af2_conf.seed),
            '--model-type',
            self._af2_conf.model_type,
            '--num-models',
            str(self._af2_conf.num_models),
        ]
        if self._af2_conf.num_models > 1:
            af2_args.append('--rank')
            af2_args.append(self._af2_conf.rank)
        if self._af2_conf.use_amber_relax:
            af2_args.append('--amber')
            af2_args.append('--num-relax')
            af2_args.append(str(self._af2_conf.num_relax))
            if self._af2_conf.use_gpu_relax:
                af2_args.append('--use-gpu-relax')

        # Run AF2
        while ret_af2 < 0:
            try:
                process_af2 = subprocess.Popen(
                    af2_args,
                    stdout=subprocess.DEVNULL,
                    stderr=subprocess.STDOUT
                )

                ret_af2 = process_af2.wait()
            except Exception as e:
                num_tries_af2 += 1
                self._log.info(f'Hmm...Maybe some error occurs during executing AlphaFold2. Tried {num_tries_af2}/5')
                torch.cuda.empty_cache()
                if num_tries_af2 > 10:
                    raise e

class MotifEvaluator:

    def __init__(
        self, 
        conf:DictConfig,
        conf_overrides: Dict=None
        ):

        self._log = logging.getLogger(self.__class__.__name__)
        logging.getLogger("matplotlib.font_manager").setLevel(logging.ERROR)

        OmegaConf.set_struct(conf, False)

        self._conf = conf
        self._infer_conf = conf.inference
        self._eval_conf = conf.evaluation
        self._result_dir = self._infer_conf.output_dir
        self._motif_pdb = self._infer_conf.motif_pdb

        self._foldseek_path = self._eval_conf.foldseek_path
        self._foldseek_database = self._eval_conf.foldseek_database
        self._package_dir = "/".join(scaffold_lab.__path__._path[0].split("/")[:-1])
        self._assist_protein_path = os.path.join(self._package_dir, self._eval_conf.assist_protein)
        self._tm_threshold = self._eval_conf.tmscore_threshold
        self._visualize = self._eval_conf.visualize

        self.folding_method = self._infer_conf.predict_method

        self._rng = np.random.default_rng(self._infer_conf.seed)

        # Hardware resources
        if self._eval_conf.foldseek_cores_for_pdbTM != "None":
            self._num_cpu_cores = self._eval_conf.foldseek_cores_for_pdbTM
            self._log.info(f"""You're using {self._num_cpu_cores} for Foldseek-search.
            You can set this value to `None` in configuration if you want to try maximizing your CPU utility
            to speed up evaluation process.""")
        else:
            self._num_cpu_cores = os.cpu_count()
            self._log.info(f"""Detecting {self._num_cpu_cores}, trying to maximize CPU utility for Foldseek-search.
            If you're using multiple GPUs and detecting slow evaluation process,
            it is recommend to set `evaluation.foldseek_cores.for_pdbTM` in configuration.
            """)

        # Merge results into one csv file
        if 'ESMFold' in self.folding_method and 'AlphaFold2' in self.folding_method:
            self.prefix = 'joint'
        elif 'ESMFold' in self.folding_method and 'AlphaFold2' not in self.folding_method:
            self.prefix = 'esm'
        else:
            self.prefix = 'af2'


    def _process_results(self, prefix: str):
        """Process results for a single folding method."""
        results_df, pdb_count = au.csv_merge(root_dir=self._result_dir, prefix=prefix)

        # Analyze outputs
        complete_results, summary_results, designability_count, backbones = au.analyze_success_rate(
            merged_data=results_df, group_mode="all", prefix=prefix
        )

        summary_csv_path = os.path.join(self._result_dir, f"{prefix}_summary_results.csv")
        complete_csv_path = os.path.join(self._result_dir, f"{prefix}_complete_results.csv")
        complete_results.to_csv(complete_csv_path, index=False)
        summary_column_order = [
            "sample_idx",
            "Success",
            "rmsd",
            "motif_rmsd",
            "length",
            "sequence",
            "sample_path",
            "backbone_path",
        ]
        summary_results.to_csv(summary_csv_path, columns=summary_column_order, index=False)

        return complete_results, backbones, designability_count, pdb_count


    def _evaluate_diversity(
        self, 
        backbones: set, 
        prefix: str
        ):
        """Run diversity evaluation."""
        successful_backbone_dir = os.path.join(self._result_dir, f"{prefix}_successful_backbones")
        os.makedirs(successful_backbone_dir, exist_ok=True)

        for pdb in backbones:
            shutil.copy(pdb, os.path.join(successful_backbone_dir, os.path.basename(pdb)))

        diversity = du.foldseek_cluster(
            input=successful_backbone_dir,
            assist_protein_path=self._assist_protein_path,
            tmscore_threshold=self._tm_threshold,
            alignment_type=1,
            output_mode="DICT",
            save_tmp=True,
            foldseek_path=self._foldseek_path,
        )
        self._log.info(
            f"Diversity Calculation for {prefix} finished.\t"
            f"Designable scaffolds: {diversity['Samples']}\t"
            f"Unique solutions: {diversity['Clusters']}"
        )

        # Create unique designable backbone directory
        diversity_result_path = os.path.join(successful_backbone_dir, "diversity_cluster.tsv")
        unique_backbones_dir = os.path.join(self._result_dir, f"{prefix}_unique_designable_backbones")
        os.makedirs(unique_backbones_dir, exist_ok=True)

        cluster_centers = set()
        cluster_dict = {}

        if os.path.exists(diversity_result_path):
            with open(diversity_result_path, "r") as f:
                cluster_info = f.readlines()

            cluster_map = defaultdict(list)
            for line in cluster_info:
                center, member = line.strip().split("\t")
                cluster_map[center].append(member)
            cluster_map.pop("assist_protein.pdb", None)

            for idx, (center, members) in enumerate(cluster_map.items(), start=1):
                cluster_centers.add(center)
                cluster_dict[str(idx)] = {"center": center, "member": members}

            if "assist_protein.pdb" in cluster_centers:
                cluster_info.remove("assist_protein.pdb")

            for pdb in cluster_centers:
                old_path = os.path.join(successful_backbone_dir, pdb)
                shutil.copy(old_path, unique_backbones_dir)
        else:
            self._log.info(
                f"Diversity results for {prefix} not found. Please check if Foldseek clustered properly or no designable backbones are present."
            )

        return diversity, successful_backbone_dir, unique_backbones_dir, cluster_dict


    def _evaluate_novelty(
        self, 
        complete_results: Union[str, Path, pd.DataFrame], 
        successful_backbone_dir: Union[str, Path], 
        unique_backbones_dir: Union[str, Path],
        clusters: Dict,
        prefix: str = "esm"
        ):
        """Run novelty evaluation."""
        success_results = complete_results[complete_results["Success"] == True]
        novelty_csv_path = os.path.join(self._result_dir, f"{prefix}_novelty_results.csv")
        if os.listdir(successful_backbone_dir):
            if not os.path.exists(novelty_csv_path): 
                results_with_novelty = nu.calculate_novelty(
                    input_csv=success_results,
                    foldseek_database_path=self._eval_conf.foldseek_database,
                    max_workers=self._num_cpu_cores,
                    cpu_threshold=75.0,
                )
            else:
                results_with_novelty = pd.read_csv(novelty_csv_path)
                self._log.info(f"Novelty results already exist. Continuing...")

            unique_backbones = results_with_novelty[results_with_novelty["sample_idx"] == 1]
            novelty_lookup = dict(zip(unique_backbones["backbone_path"].apply(os.path.basename), unique_backbones["pdbTM"]))

            for cluster_id, cluster_info in clusters.items():
                center = cluster_info["center"]
                members = cluster_info["member"]

                cluster_novelty_values = [novelty_lookup.get(member, None) for member in members]
                cluster_novelty_values = [val for val in cluster_novelty_values if val is not None]

                if cluster_novelty_values:
                    mean_novelty = sum(cluster_novelty_values) / len(cluster_novelty_values)
                    clusters[cluster_id]["mean_novelty"] = mean_novelty
                else:
                    clusters[cluster_id]["mean_novelty"] = None

            # Weighted novelty across clusters
            novelty_values = [cluster_info["mean_novelty"] for cluster_info in clusters.values()]
            weighted_novelty = sum(novelty_values) / len(novelty_values)

            if len(os.listdir(unique_backbones_dir)) != len(novelty_values):
                self._log.warning(f"""
            Incompatible numbers of clusters{len(os.listdir(unique_backbones_dir))} 
            and number of novelty results {len(novelty_values)}, please have a check!
            """)

            novelty_score = 1 - weighted_novelty
            max_novelty = results_with_novelty["pdbTM"].min()
            self._log.info(
                f"Novelty Calculation for {prefix} finished.\n"
                f"Novelty score (1 - pdbTM) among successful backbones weighted by number of clusters: {novelty_score:.3f}\n"
                f"The most novel designable backbone has a pdbTM of {max_novelty:.3f}"
            )
            results_with_novelty.to_csv(novelty_csv_path, index=False)
        else:
            self._log.info(f"No successful backbone was found for {prefix}. Skipping novelty calculation.")
            novelty_score = 0
        return novelty_score


    def run_evaluation(self):
        """Run evaluation for all specified folding methods."""
        diversity_results = {}
        novelty_results = {}
        designability_counts = {}
        pdb_counts = {}

        for method in self.folding_method:
            self._log.info(f"Processing results for folding method: {method}")
            prefix = "esm" if method == "ESMFold" else "af2"

            # Process results and calculate diversity and novelty
            complete_results, backbones, designability_count, pdb_count = self._process_results(prefix)
            diversity, successful_backbone_dir, unique_clusters, clusters_information = self._evaluate_diversity(backbones, prefix)
            novelty_score = self._evaluate_novelty(
                complete_results=complete_results,
                successful_backbone_dir=successful_backbone_dir,
                unique_backbones_dir=unique_clusters,
                clusters=clusters_information, 
                prefix=prefix)

            # Collect results
            diversity_results[prefix] = diversity
            novelty_results[prefix] = novelty_score
            designability_counts[prefix] = designability_count
            pdb_counts[prefix] = pdb_count

        # Write summary outputs
        for prefix in diversity_results.keys():
            au.write_summary_results(
                stored_path=self._result_dir,
                pdb_count=pdb_counts[prefix],
                designable_count=designability_counts[prefix],
                diversity_result=diversity_results[prefix],
                novelty_value=novelty_results[prefix],
                prefix=prefix
            )

        # Optional visualization
        if self._visualize:
            for method in self.folding_method:
                self._log.info(f"Performing visualization for {method}.")
                prefix = "esm" if method == "ESMFold" else "af2"
                pu.plot_metrics_distribution(
                    input=os.path.join(self._result_dir, f"{prefix}_complete_results.csv"),
                    save_path=self._result_dir,
                    prefix=prefix
                )

                pu.plot_novelty_distribution(
                    input=os.path.join(self._result_dir, f"{prefix}_success_novelty_results.csv"),
                    save_path=self._result_dir,
                    prefix=prefix
                )

                pymol_reference_pdb = os.path.join(self._motif_pdb)

                pu.motif_scaffolding_pymol_write(
                    unique_designable_backbones=os.path.join(self._result_dir, f'{prefix}_unique_designable_backbones'),
                    reference_pdb=pymol_reference_pdb,
                    motif_json=os.path.join(self._result_dir, 'motif_info.json'),
                    save_path=os.path.join(self._result_dir, f'{prefix}_pymol_session.pse')
                    )   


@hydra.main(version_base=None, config_path="../../config",
        config_name="motif_scaffolding.yaml")
def run(conf: DictConfig) -> None:


    # Check that path to foldseek database has been specified
    if not conf.evaluation.get("foldseek_database"):
        raise ValueError("The 'foldseek_database' must be specified in the configuration.")

    # Perform fixed backbone design and forward folding
    print('Starting refolding for motif-scaffolding task......')
    start_time = time.time()
    refolder = MotifRefolder(conf)
    refolder.run_sampling()
    elapsed_time = time.time() - start_time
    print(f"Refolding finished in {elapsed_time:.2f}s.")

    # Perform analysis on outputs
    start_time = time.time()
    evaluator = MotifEvaluator(conf)
    evaluator.run_evaluation()
    elapsed_time = time.time() - start_time
    print(f'Evaluation finished in {elapsed_time:.2f}s. Voila!')

if __name__ == '__main__':
    run()
